{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrn7vPkBzL1I"
      },
      "outputs": [],
      "source": [
        "# Required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data\n",
        "def load_data(filepath):\n",
        "    \"\"\" Load a dataset from a specified file path. \"\"\"\n",
        "    data = pd.read_csv(filepath)\n",
        "    print(f\"Loaded data with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
        "    return data"
      ],
      "metadata": {
        "id": "d7vzFZvazmrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display data information\n",
        "def display_data_info(df):\n",
        "    \"\"\" Display basic information and the first 10 rows of the DataFrame. \"\"\"\n",
        "    print(df.info())\n",
        "    print(\"First 5 rows of the dataset:\")\n",
        "    print(df.head(5))"
      ],
      "metadata": {
        "id": "5RQX2BIFzmKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot distribution of the target variable\n",
        "def plot_target_distribution(df, target):\n",
        "    \"\"\" Plot the distribution of the target variable. \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[target], kde=True)\n",
        "    plt.title('Distribution of ' + target)\n",
        "    plt.xlabel(target)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GTecKAxTzi40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot missing data\n",
        "def plot_missing_data(df):\n",
        "    \"\"\" Plot missing data counts for each feature. \"\"\"\n",
        "    missing = df.isnull().sum()\n",
        "    missing = missing[missing > 0]\n",
        "    missing.sort_values(inplace=True)\n",
        "    missing.plot.bar()\n",
        "    plt.title('Missing data count by feature')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bfzCVw71ziZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot correlation matrix\n",
        "def plot_correlation_matrix(df, features):\n",
        "    \"\"\" Plot the correlation matrix for selected features. \"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(df[features].corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OCXdMsapzgUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create preprocessor for numeric and categorical data\n",
        "def create_preprocessor(numeric_features, categorical_features):\n",
        "    \"\"\" Create a column transformer for preprocessing the data. \"\"\"\n",
        "    numeric_transformer = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    return ColumnTransformer([\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "sz-iHPwIzdjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to select features based on correlation and missing data\n",
        "def select_features(df, target='SalePrice', corr_threshold=0.5, missing_threshold=0.2):\n",
        "    \"\"\" Select features based on correlation with target and missing data percentage. \"\"\"\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    corr_matrix = numeric_df.corr()\n",
        "    high_corr_features = corr_matrix[target][corr_matrix[target].abs() > corr_threshold].index.tolist()\n",
        "    missing_data = df.isnull().mean()\n",
        "    low_missing_features = missing_data[missing_data < missing_threshold].index.tolist()\n",
        "    selected_features = list(set(high_corr_features) & set(low_missing_features))\n",
        "    if target in selected_features:\n",
        "        selected_features.remove(target)\n",
        "    return selected_features"
      ],
      "metadata": {
        "id": "r-8BavtxzZ3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train a Gradient Boosting model and return it\n",
        "def train_model(X_train, y_train):\n",
        "    \"\"\" Train a Gradient Boosting Regressor model. \"\"\"\n",
        "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ],
      "metadata": {
        "id": "-ILSCj_ozX1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_train, y_train):\n",
        "    \"\"\" Evaluate the model using RMSE, R-squared, and MAE. \"\"\"\n",
        "    predictions = model.predict(X_train)\n",
        "    rmse = np.sqrt(mean_squared_error(y_train, predictions))\n",
        "    r2 = r2_score(y_train, predictions)\n",
        "    mae = mean_absolute_error(y_train, predictions)\n",
        "    print(f\"Model Performance: RMSE = {rmse}, R^2 = {r2}, MAE = {mae}\")"
      ],
      "metadata": {
        "id": "u6FHrKE_zXLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run the analysis\n",
        "def main():\n",
        "    # Paths to the dataset\n",
        "    train_path = '/kaggle/input/house-prices-advanced-regression-techniques/train.csv'\n",
        "    test_path = '/kaggle/input/house-prices-advanced-regression-techniques/test.csv'\n",
        "    sample_submission_path = '/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv'\n",
        "\n",
        "    # Load datasets\n",
        "    train = load_data(train_path)\n",
        "    test = load_data(test_path)\n",
        "    sample_submission_df = load_data(sample_submission_path)\n",
        "\n",
        "    # Display data information\n",
        "    display_data_info(train)\n",
        "\n",
        "    # Plotting the distribution of 'SalePrice'\n",
        "    plot_target_distribution(train, 'SalePrice')\n",
        "\n",
        "    # Plotting missing data\n",
        "    plot_missing_data(train)\n",
        "\n",
        "    # Feature selection\n",
        "    features = select_features(train)\n",
        "    print(\"Selected features based on correlation and missing data:\", features)\n",
        "\n",
        "    # Plot correlation matrix for selected features\n",
        "    plot_correlation_matrix(train, features + ['SalePrice'])\n",
        "\n",
        "    # Preprocessing\n",
        "    numeric_features = train[features].select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_features = train[features].select_dtypes(include=['object']).columns.tolist()\n",
        "    preprocessor = create_preprocessor(numeric_features, categorical_features)\n",
        "\n",
        "    # Preparing the data\n",
        "    X_train = preprocessor.fit_transform(train[features])\n",
        "    y_train = train['SalePrice']\n",
        "    X_test = preprocessor.transform(test[features])\n",
        "\n",
        "    # Model training and evaluation\n",
        "    model = train_model(X_train, y_train)\n",
        "    evaluate_model(model, X_train, y_train)\n",
        "\n",
        "    # Making predictions and preparing the submission file\n",
        "    sample_submission_df['SalePrice'] = model.predict(X_test)\n",
        "    submission_file_path = '/kaggle/working/submission.csv'\n",
        "    sample_submission_df.to_csv(submission_file_path, index=False)\n",
        "    print(f\"Submission file has been created at {submission_file_path}\")\n",
        "    print(sample_submission_df.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "7DNup4ihzVEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}